{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path('./dataset/')\n",
    "AL = DATA_FOLDER/'AL'\n",
    "AL_train = AL/'train'\n",
    "AL_dev_x = AL/'dev.in'\n",
    "AL_dev_y = AL/'dev.out'\n",
    "AL_out_2 = AL/'dev.p2.out'\n",
    "\n",
    "SG = DATA_FOLDER/'SG'\n",
    "SG_train = SG/'train'\n",
    "SG_dev_x = SG/'dev.in'\n",
    "SG_dev_y = SG/'dev.out'\n",
    "SG_out_2 = SG/'dev.p2.out'\n",
    "\n",
    "CN = DATA_FOLDER/'CN'\n",
    "CN_train = CN/'train'\n",
    "CN_dev_x = CN/'dev.in'\n",
    "CN_dev_y = CN/'dev.out'\n",
    "CN_out_2 = CN/'dev.p2.out'\n",
    "\n",
    "EN = DATA_FOLDER/'EN'\n",
    "EN_train = EN/'train'\n",
    "EN_dev_x = EN/'dev.in'\n",
    "EN_dev_y = EN/'dev.out'\n",
    "EN_out_2 = EN/'dev.p2.out'\n",
    "\n",
    "EVAL_script = './EvalScript/evalResult.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    x, y = [], []\n",
    "    temp_x, temp_y = [], []\n",
    "    for l in lines:\n",
    "        if len(l) == 1:\n",
    "            assert(len(temp_x) == len(temp_y))\n",
    "            x.append(temp_x)\n",
    "            y.append(temp_y)\n",
    "            temp_x, temp_y = [], []\n",
    "            continue\n",
    "        xx, yy = l.split()\n",
    "        temp_x.append(xx)\n",
    "        temp_y.append(yy)\n",
    "    if len(temp_x) != 0:\n",
    "        x.append(temp_x)\n",
    "        y.append(temp_y)\n",
    "    assert(len(x) == len(y))\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def get_test_data(filename, word2index):\n",
    "    \"\"\"Return:\n",
    "                x: nested list of string\n",
    "                x_int: nested list of integer\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    x = []\n",
    "    temp_x = []\n",
    "    for l in lines:\n",
    "        if len(l.strip()) == 0:\n",
    "            x.append(temp_x)\n",
    "            temp_x = []\n",
    "            continue\n",
    "        xx = l.split()\n",
    "        temp_x.append(xx[0])\n",
    "    if len(temp_x) != 0:\n",
    "        x.append(temp_x)\n",
    "    x_int = [[word2index[oo] for oo in o] for o in x ]\n",
    "    return x, x_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = get_train_data(AL_train)\n",
    "vocab = list(set([oo for o in words for oo in o]))\n",
    "tags = list(set([oo for o in labels for oo in o])) + ['SOS', 'EOS']\n",
    "word2index = {o:i for i,o in enumerate(vocab)}\n",
    "index2word = {i:o for i,o in enumerate(vocab)}\n",
    "tag2index = {o:i for i,o in enumerate(tags)}\n",
    "x = [[word2index[oo] for oo in o] for o in words]\n",
    "y = [[tag2index[oo] for oo in o] for o in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1 Emission features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission(x, y, vocab, tags):\n",
    "    emission = np.zeros((len(vocab), len(tags)))\n",
    "    flat_y = [oo for o in y for oo in o]\n",
    "    flat_x = [oo for o in x for oo in o]\n",
    "    for xx, yy in zip(flat_x,flat_y):\n",
    "        emission[xx, yy] += 1\n",
    "    \n",
    "    y_count = np.zeros(len(tags))\n",
    "    for yy in flat_y:\n",
    "        y_count[yy] += 1\n",
    "    emission = emission/ y_count[None, :]\n",
    "    np.nan_to_num(emission, 0)\n",
    "    return emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission_matrix shape (vocab, tags):  (5321, 44)\n",
      "transition_matrix shape (transition_from, transition_to):  (44, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "emission_matrix = emission(x, y)\n",
    "print(\"emission_matrix shape (vocab, tags): \", emission_matrix.shape)\n",
    "transition_matrix = transition(y)\n",
    "print(\"transition_matrix shape (transition_from, transition_to): \", transition_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Adding smoothing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "vocab_count = Counter([oo for o in words for oo in o])\n",
    "vocab = [o for o, v in dict(vocab_count).items() if v>=3] + ['#UNK#']\n",
    "word2index = defaultdict(int)\n",
    "for i,o in enumerate(vocab): word2index[o] = i+1\n",
    "x = [ [word2index[oo] for oo in o] for o in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission_matrix shape (vocab, tags):  (2698, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "emission_matrix = emission(x, y)\n",
    "print(\"emission_matrix shape (vocab, tags): \", emission_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding(x, emission_matrix):\n",
    "    \"\"\"emission matrix: (vocab_size, tag_size)\n",
    "    x: converted to integer arrays\"\"\"\n",
    "    return emission_matrix[x].argmax(axis=1)\n",
    "\n",
    "def batch_decoding(output_filename, dev_x_filename, word2index, emission_matrix, tags):\n",
    "    with open(output_filename, 'w') as f:\n",
    "        words, dev_x = get_test_data(dev_x_filename, word2index)\n",
    "        for ws,o in zip(words, dev_x):\n",
    "            path = decoding(o, emission_matrix)\n",
    "            for w, p in zip(ws, path):\n",
    "                f.write(w + ' ' + tags[p] + '\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab everythings together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_file, output_filename, dev_x_filename):\n",
    "    # read data\n",
    "    words, labels = get_train_data(train_file)\n",
    "    # create vocab\n",
    "    tags = list(set([oo for o in labels for oo in o])) + ['SOS', 'EOS']\n",
    "    tag2index = {o:i for i,o in enumerate(tags)}\n",
    "    vocab_count = Counter([oo for o in words for oo in o])\n",
    "    vocab = [o for o, v in dict(vocab_count).items() if v>=3] + ['#UNK#']\n",
    "    word2index = defaultdict(int)\n",
    "    for i,o in enumerate(vocab): word2index[o] = i+1\n",
    "    # text to int\n",
    "    x = [[word2index[oo] for oo in o] for o in words]\n",
    "    y = [[tag2index[oo] for oo in o] for o in labels]\n",
    "    # training\n",
    "    emission_matrix = emission(x, y, vocab, tags)\n",
    "    # decoding\n",
    "    batch_decoding(output_filename, dev_x_filename, word2index, emission_matrix, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 8408\r\n",
      "#Entity in prediction: 19484\r\n",
      "\r\n",
      "#Correct Entity : 2898\r\n",
      "Entity  precision: 0.1487\r\n",
      "Entity  recall: 0.3447\r\n",
      "Entity  F: 0.2078\r\n",
      "\r\n",
      "#Correct Sentiment : 2457\r\n",
      "Sentiment  precision: 0.1261\r\n",
      "Sentiment  recall: 0.2922\r\n",
      "Sentiment  F: 0.1762\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "main(AL_train, AL_out_2, AL_dev_x)\n",
    "! python {EVAL_script} {AL_dev_y} {AL_out_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 4537\r\n",
      "#Entity in prediction: 18451\r\n",
      "\r\n",
      "#Correct Entity : 2632\r\n",
      "Entity  precision: 0.1426\r\n",
      "Entity  recall: 0.5801\r\n",
      "Entity  F: 0.2290\r\n",
      "\r\n",
      "#Correct Sentiment : 1239\r\n",
      "Sentiment  precision: 0.0672\r\n",
      "Sentiment  recall: 0.2731\r\n",
      "Sentiment  F: 0.1078\r\n"
     ]
    }
   ],
   "source": [
    "main(SG_train, SG_out_2, SG_dev_x)\n",
    "! python {EVAL_script} {SG_dev_y} {SG_out_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 13179\r\n",
      "#Entity in prediction: 19406\r\n",
      "\r\n",
      "#Correct Entity : 9152\r\n",
      "Entity  precision: 0.4716\r\n",
      "Entity  recall: 0.6944\r\n",
      "Entity  F: 0.5617\r\n",
      "\r\n",
      "#Correct Sentiment : 7644\r\n",
      "Sentiment  precision: 0.3939\r\n",
      "Sentiment  recall: 0.5800\r\n",
      "Sentiment  F: 0.4692\r\n"
     ]
    }
   ],
   "source": [
    "main(EN_train, EN_out_2, EN_dev_x)\n",
    "! python {EVAL_script} {EN_dev_y} {EN_out_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 1478\r\n",
      "#Entity in prediction: 9373\r\n",
      "\r\n",
      "#Correct Entity : 765\r\n",
      "Entity  precision: 0.0816\r\n",
      "Entity  recall: 0.5176\r\n",
      "Entity  F: 0.1410\r\n",
      "\r\n",
      "#Correct Sentiment : 285\r\n",
      "Sentiment  precision: 0.0304\r\n",
      "Sentiment  recall: 0.1928\r\n",
      "Sentiment  F: 0.0525\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/pengfei/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "main(CN_train, CN_out_2, CN_dev_x)\n",
    "! python {EVAL_script} {CN_dev_y} {CN_out_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_file, output_filename, dev_x_filename):\n",
    "    # read data\n",
    "    words, labels = get_train_data(AL_train)\n",
    "    # create vocab\n",
    "    tags = list(set([oo for o in labels for oo in o])) + ['SOS', 'EOS']\n",
    "    tag2index = {o:i for i,o in enumerate(tags)}\n",
    "    vocab_count = Counter([oo for o in words for oo in o])\n",
    "    vocab = [o for o, v in dict(vocab_count).items() if v>=3] + ['#UNK#']\n",
    "    word2index = defaultdict(int)\n",
    "    for i,o in enumerate(vocab): word2index[o] = i+1\n",
    "    # text to int\n",
    "    x = [[word2index[oo] for oo in o] for o in words]\n",
    "    y = [[tag2index[oo] for oo in o] for o in labels]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(y):\n",
    "    SOS = tag2index['SOS']\n",
    "    EOS = tag2index['EOS']\n",
    "    y = [[SOS]+o+[EOS] for o in y]\n",
    "    transition = np.zeros((len(tags), len(tags)))\n",
    "    \n",
    "    for yy in y:\n",
    "        for i in range(len(yy)-1):\n",
    "            start = yy[i]\n",
    "            end = yy[i+1]\n",
    "            transition[start, end] += 1\n",
    "    \n",
    "    transition = transition/np.sum(transition, axis=1)\n",
    "    return transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(x, transition_matrix, emission_matrix):\n",
    "    score = np.ones( (len(x)+1, len(tags)) )\n",
    "    transition_matrix, emission_matrix = np.log(transition_matrix), np.log(emission_matrix)\n",
    "    for step in range(1, len(score)):\n",
    "        for state in range(len(score[step])):\n",
    "            score[step, state] = np.max(score[step-1] + transition[:, state]) + emission_matrix[x[step], state]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_path = viterbi_decoding(x, transition_matrix, emission_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
