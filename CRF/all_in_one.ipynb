{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import permutations\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    with open(file_path,'r') as f:\n",
    "        data = f.readlines()\n",
    "    data = [item.rstrip('\\n').split(' ') for item in data]\n",
    "    s_data = []\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        if d[0]:\n",
    "            new_data.append(d)\n",
    "        else:\n",
    "            s_data.append(new_data)\n",
    "            new_data = []\n",
    "    return s_data\n",
    "\n",
    "def read_template(template_path):\n",
    "    with open(template_path) as f:\n",
    "        template = f.readlines()\n",
    "    template = [t.rstrip('\\n') for t in template if t[0] in ['U','B']]\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6a115dfddf45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = r'data\\small_train.data'\n",
    "train_data = read_data(data_file_path)\n",
    "template_path = r'data\\template'\n",
    "template = read_template(template_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_LABEL = '@@'\n",
    "START_LABEL_IDX = 0\n",
    "STOP_LABEL = '##'\n",
    "SEP1 = '^^'\n",
    "SEP2 = '%%'\n",
    "\n",
    "class Feature():\n",
    "    def __init__(self, data):\n",
    "        self.X = data\n",
    "        self.labels = Counter()\n",
    "        self.feats = Counter()\n",
    "        self.feats2idx = dict()\n",
    "        self.labels2idx = dict()\n",
    "        self.feats_size, self.labels_size = 0, 0\n",
    "        \n",
    "        self.label_dic = {START_LABEL: START_LABEL_IDX}\n",
    "        self.label_array = [START_LABEL]\n",
    "        self.num_features = 0\n",
    "        self.feature_dic = dict()\n",
    "        self.observation_set = set()\n",
    "        self.empirical_counts = Counter()\n",
    "        #self.valid_featfunc_in_data = Counter()\n",
    "    \n",
    "    \n",
    "    def get_sentence_feats_labels(self, sent):\n",
    "        feats, labels = [], []\n",
    "        featfunc_in_sent = defaultdict(int)\n",
    "        sent_len = len(sent)\n",
    "        featfunc_in_sent_position = defaultdict(list)\n",
    "        for idx_w, w in enumerate(sent):\n",
    "            labels.append(w[-1])\n",
    "            feats.append('U02:%s' % w[0])\n",
    "            feats.append('U12:%s' % w[1])\n",
    "            ###\n",
    "            featfunc_in_sent['U02:%s' % w[0] + SEP1 + w[-1]] += 1\n",
    "            featfunc_in_sent['U12:%s' % w[1] + SEP1 + w[-1]] += 1\n",
    "            featfunc_in_sent_position['U02:%s' % w[0] + SEP1 + w[-1]].append(idx_w)\n",
    "            featfunc_in_sent_position['U12:%s' % w[1] + SEP1 + w[-1]].append(idx_w)\n",
    "            if idx_w>0:\n",
    "                if idx_w < sent_len-1:\n",
    "                    featfunc_in_sent['U02:%s' % w[0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U12:%s' % w[1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] += 1\n",
    "                    featfunc_in_sent_position['U02:%s' % w[0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U12:%s' % w[1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                else:\n",
    "                    featfunc_in_sent['U02:%s' % w[0] + SEP1 + w[-1] + SEP2 + STOP_LABEL] += 1\n",
    "                    featfunc_in_sent['U12:%s' % w[1] + SEP1 + w[-1] + SEP2 + STOP_LABEL] += 1\n",
    "                    featfunc_in_sent_position['U02:%s' % w[0] + SEP1 + w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                    featfunc_in_sent_position['U12:%s' % w[1] + SEP1 + w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                    \n",
    "            else:\n",
    "                featfunc_in_sent['U02:%s' % w[0] + SEP1 + START_LABEL + SEP2 + w[-1]] += 1\n",
    "                featfunc_in_sent['U12:%s' % w[1] + SEP1 + START_LABEL + SEP2 + w[-1]] += 1\n",
    "                featfunc_in_sent_position['U02:%s' % w[0] + SEP1 + START_LABEL + SEP2 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U12:%s' % w[1] + SEP1 + START_LABEL + SEP2 + w[-1]].append(idx_w)\n",
    "            \n",
    "            if idx_w < sent_len-1:\n",
    "                feats.append('U03:%s' % sent[idx_w+1][0])\n",
    "                feats.append('U13:%s' % sent[idx_w+1][1])\n",
    "                feats.append('U06:%s/%s' % (w[0], sent[idx_w+1][0]))\n",
    "                feats.append('U17:%s/%s' % (w[1], sent[idx_w+1][1]))\n",
    "                \n",
    "                featfunc_in_sent['U03:%s' % sent[idx_w+1][0] + SEP1 + w[-1]] += 1\n",
    "                featfunc_in_sent['U13:%s' % sent[idx_w+1][1] + SEP1 + w[-1]] += 1\n",
    "                featfunc_in_sent['U06:%s/%s' % (w[0], sent[idx_w+1][0]) + SEP1 + w[-1]] += 1\n",
    "                featfunc_in_sent['U17:%s/%s' % (w[1], sent[idx_w+1][1]) + SEP1 + w[-1]] += 1\n",
    "                featfunc_in_sent_position['U03:%s' % sent[idx_w+1][0] + SEP1 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U13:%s' % sent[idx_w+1][1] + SEP1 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U06:%s/%s' % (w[0], sent[idx_w+1][0]) + SEP1 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U17:%s/%s' % (w[1], sent[idx_w+1][1]) + SEP1 + w[-1]].append(idx_w)\n",
    "                \n",
    "                if idx_w < sent_len-2:\n",
    "                    feats.append('U04:%s' % sent[idx_w+2][0])\n",
    "                    feats.append('U14:%s' % sent[idx_w+2][1])\n",
    "                    feats.append('U18:%s/%s' % (sent[idx_w+1][1],sent[idx_w+2][1]))\n",
    "                    feats.append('U22:%s/%s/%s' % (w[1],sent[idx_w+1][1],sent[idx_w+2][1]))\n",
    "                    \n",
    "                    featfunc_in_sent['U04:%s' % sent[idx_w+2][0] + SEP1 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U14:%s' % sent[idx_w+2][1] + SEP1 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U18:%s/%s' % (sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U22:%s/%s/%s' % (w[1],sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + w[-1]] += 1\n",
    "                    featfunc_in_sent_position['U04:%s' % sent[idx_w+2][0] + SEP1 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U14:%s' % sent[idx_w+2][1] + SEP1 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U18:%s/%s' % (sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U22:%s/%s/%s' % (w[1],sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + w[-1]].append(idx_w)\n",
    "                    \n",
    "                    \n",
    "                if idx_w > 0:\n",
    "                    feats.append('U21:%s/%s/%s' % (sent[idx_w-1][1],w[1],sent[idx_w+1][1]))\n",
    "                    \n",
    "                    featfunc_in_sent['U21:%s/%s/%s' % (sent[idx_w-1][1],w[1],sent[idx_w+1][1]) + SEP1 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U21:%s/%s/%s' % (sent[idx_w-1][1],w[1],sent[idx_w+1][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] += 1\n",
    "                    featfunc_in_sent_position['U21:%s/%s/%s' % (sent[idx_w-1][1],w[1],sent[idx_w+1][1]) + SEP1 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U21:%s/%s/%s' % (sent[idx_w-1][1],w[1],sent[idx_w+1][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    \n",
    "                    featfunc_in_sent['U03:%s' % sent[idx_w+1][0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U13:%s' % sent[idx_w+1][1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U06:%s/%s' % (w[0], sent[idx_w+1][0]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U17:%s/%s' % (w[1], sent[idx_w+1][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] += 1\n",
    "                    if idx_w < sent_len-2:\n",
    "                        featfunc_in_sent['U04:%s' % sent[idx_w+2][0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                        featfunc_in_sent['U14:%s' % sent[idx_w+2][1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                        featfunc_in_sent['U18:%s/%s' % (sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                        featfunc_in_sent['U22:%s/%s/%s' % (w[1],sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                        featfunc_in_sent_position['U04:%s' % sent[idx_w+2][0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                        featfunc_in_sent_position['U14:%s' % sent[idx_w+2][1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                        featfunc_in_sent_position['U18:%s/%s' % (sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                        featfunc_in_sent_position['U22:%s/%s/%s' % (w[1],sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                        \n",
    "                        \n",
    "                    featfunc_in_sent_position['U03:%s' % sent[idx_w+1][0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U13:%s' % sent[idx_w+1][1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U06:%s/%s' % (w[0], sent[idx_w+1][0]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U17:%s/%s' % (w[1], sent[idx_w+1][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "\n",
    "                else:\n",
    "                    featfunc_in_sent['U03:%s' % sent[idx_w+1][0] + SEP1 + START_LABEL + SEP2 + w[-1]] += 1\n",
    "                    featfunc_in_sent['U13:%s' % sent[idx_w+1][1] + SEP1 + START_LABEL + SEP2 +  w[-1]] += 1\n",
    "                    featfunc_in_sent['U06:%s/%s' % (w[0], sent[idx_w+1][0]) + SEP1 + START_LABEL + SEP2 +  w[-1]] += 1\n",
    "                    featfunc_in_sent['U17:%s/%s' % (w[1], sent[idx_w+1][1]) + SEP1 + START_LABEL + SEP2 +  w[-1]] += 1\n",
    "                    featfunc_in_sent['U04:%s' % sent[idx_w+2][0] + SEP1 + START_LABEL + SEP2 +  w[-1]] += 1\n",
    "                    featfunc_in_sent['U14:%s' % sent[idx_w+2][1] + SEP1 + START_LABEL + SEP2 +  w[-1]] += 1\n",
    "                    featfunc_in_sent['U18:%s/%s' % (sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + START_LABEL + SEP2 +  w[-1]] += 1\n",
    "                    featfunc_in_sent['U22:%s/%s/%s' % (w[1],sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + START_LABEL + SEP2 +  w[-1]] += 1\n",
    "                    \n",
    "                    featfunc_in_sent_position['U03:%s' % sent[idx_w+1][0] + SEP1 + START_LABEL + SEP2 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U13:%s' % sent[idx_w+1][1] + SEP1 + START_LABEL + SEP2 +  w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U06:%s/%s' % (w[0], sent[idx_w+1][0]) + SEP1 + START_LABEL + SEP2 +  w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U17:%s/%s' % (w[1], sent[idx_w+1][1]) + SEP1 + START_LABEL + SEP2 +  w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U04:%s' % sent[idx_w+2][0] + SEP1 + START_LABEL + SEP2 +  w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U14:%s' % sent[idx_w+2][1] + SEP1 + START_LABEL + SEP2 +  w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U18:%s/%s' % (sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + START_LABEL + SEP2 +  w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U22:%s/%s/%s' % (w[1],sent[idx_w+1][1],sent[idx_w+2][1]) + SEP1 + START_LABEL + SEP2 +  w[-1]].append(idx_w)\n",
    "                    \n",
    "                    \n",
    "            if idx_w > 0:\n",
    "                feats.append('U01:%s' % sent[idx_w-1][0])\n",
    "                feats.append('U11:%s' % sent[idx_w-1][1])\n",
    "                feats.append('U05:%s/%s' % (sent[idx_w-1][0],w[0]))\n",
    "                feats.append('U16:%s/%s' % (sent[idx_w-1][1],w[1]))\n",
    "                ###\n",
    "                featfunc_in_sent['U01:%s' % sent[idx_w-1][0] + SEP1 + w[-1]] +=1\n",
    "                featfunc_in_sent['U11:%s' % sent[idx_w-1][1] + SEP1 + w[-1]] +=1\n",
    "                featfunc_in_sent['U05:%s/%s' % (sent[idx_w-1][0],w[0]) + SEP1 + w[-1]] +=1\n",
    "                featfunc_in_sent['U16:%s/%s' % (sent[idx_w-1][1],w[1]) + SEP1 + w[-1]] +=1\n",
    "                featfunc_in_sent['U01:%s' % sent[idx_w-1][0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                featfunc_in_sent['U11:%s' % sent[idx_w-1][1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                featfunc_in_sent['U05:%s/%s' % (sent[idx_w-1][0],w[0]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                featfunc_in_sent['U16:%s/%s' % (sent[idx_w-1][1],w[1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                                              \n",
    "                featfunc_in_sent_position['U01:%s' % sent[idx_w-1][0] + SEP1 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U11:%s' % sent[idx_w-1][1] + SEP1 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U05:%s/%s' % (sent[idx_w-1][0],w[0]) + SEP1 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U16:%s/%s' % (sent[idx_w-1][1],w[1]) + SEP1 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U01:%s' % sent[idx_w-1][0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U11:%s' % sent[idx_w-1][1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U05:%s/%s' % (sent[idx_w-1][0],w[0]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                featfunc_in_sent_position['U16:%s/%s' % (sent[idx_w-1][1],w[1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                \n",
    "                if idx_w==sent_len-1:\n",
    "                    featfunc_in_sent['U01:%s' % sent[idx_w-1][0] + SEP1 + w[-1] + SEP2 + STOP_LABEL] +=1\n",
    "                    featfunc_in_sent['U11:%s' % sent[idx_w-1][1] + SEP1 + w[-1] + SEP2 + STOP_LABEL] +=1\n",
    "                    featfunc_in_sent['U05:%s/%s' % (sent[idx_w-1][0],w[0]) + SEP1 + w[-1] + SEP2 + STOP_LABEL] +=1\n",
    "                    featfunc_in_sent['U16:%s/%s' % (sent[idx_w-1][1],w[1]) + SEP1 + w[-1] + SEP2 + STOP_LABEL] +=1\n",
    "                    featfunc_in_sent_position['U01:%s' % sent[idx_w-1][0] + SEP1 + w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                    featfunc_in_sent_position['U11:%s' % sent[idx_w-1][1] + SEP1 + w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                    featfunc_in_sent_position['U05:%s/%s' % (sent[idx_w-1][0],w[0]) + SEP1 + w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                    featfunc_in_sent_position['U16:%s/%s' % (sent[idx_w-1][1],w[1]) + SEP1 + w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                \n",
    "                if idx_w > 1:\n",
    "                    feats.append('U00:%s' % sent[idx_w-2][0])\n",
    "                    feats.append('U10:%s' % sent[idx_w-2][1])\n",
    "                    feats.append('U15:%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1]))\n",
    "                    feats.append('U20:%s/%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1],w[1]))\n",
    "                    ###\n",
    "                    featfunc_in_sent['U00:%s' % sent[idx_w-2][0] + SEP1 + w[-1]] +=1\n",
    "                    featfunc_in_sent['U10:%s' % sent[idx_w-2][1] + SEP1 + w[-1]] +=1\n",
    "                    featfunc_in_sent['U15:%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1]) + SEP1 + w[-1]] +=1\n",
    "                    featfunc_in_sent['U20:%s/%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1],w[1]) + SEP1 + w[-1]] +=1\n",
    "                    featfunc_in_sent['U00:%s' % sent[idx_w-2][0]  + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                    featfunc_in_sent['U10:%s' % sent[idx_w-2][1]  + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                    featfunc_in_sent['U15:%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1])  + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                    featfunc_in_sent['U20:%s/%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1],w[1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]] +=1\n",
    "                    featfunc_in_sent_position['U00:%s' % sent[idx_w-2][0] + SEP1 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U10:%s' % sent[idx_w-2][1] + SEP1 +  w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U15:%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1]) + SEP1 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U20:%s/%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1],w[1]) + SEP1 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U00:%s' % sent[idx_w-2][0] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U10:%s' % sent[idx_w-2][1] + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U15:%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    featfunc_in_sent_position['U20:%s/%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1],w[1]) + SEP1 + sent[idx_w-1][-1] + SEP2 + w[-1]].append(idx_w)\n",
    "                    if idx_w == sent_len-1:\n",
    "                        featfunc_in_sent['U00:%s' % sent[idx_w-2][0] + SEP1 + w[-1] + SEP2 + STOP_LABEL] +=1\n",
    "                        featfunc_in_sent['U10:%s' % sent[idx_w-2][1] + SEP1 + w[-1] + SEP2 + STOP_LABEL] +=1\n",
    "                        featfunc_in_sent['U15:%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1]) + SEP1 + w[-1] + SEP2 + STOP_LABEL] +=1\n",
    "                        featfunc_in_sent['U20:%s/%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1],w[1]) + SEP1 + w[-1] + SEP2 + STOP_LABEL] +=1\n",
    "                                              \n",
    "                        featfunc_in_sent_position['U00:%s' % sent[idx_w-2][0]+ SEP1+w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                        featfunc_in_sent_position['U10:%s' % sent[idx_w-2][1]+ SEP1+w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                        featfunc_in_sent_position['U15:%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1])+ SEP1 + w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                        featfunc_in_sent_position['U20:%s/%s/%s' % (sent[idx_w-2][1],sent[idx_w-1][1],w[1])+ SEP1 + w[-1] + SEP2 + STOP_LABEL].append(idx_w)\n",
    "                            \n",
    "            \n",
    "        return feats, labels, featfunc_in_sent, featfunc_in_sent_position\n",
    "    \n",
    "    def get_word_feats(self, sent, idx):\n",
    "        sent_len = len(sent)\n",
    "        feats = list()\n",
    "        feats.append('U02:%s' % sent[idx][0])\n",
    "        feats.append('U12:%s' % sent[idx][1])\n",
    "        if idx < sent_len-1:\n",
    "            feats.append('U03:%s' % sent[idx+1][0])\n",
    "            feats.append('U13:%s' % sent[idx+1][1])\n",
    "            feats.append('U06:%s/%s' % (sent[idx][0], sent[idx+1][0]))\n",
    "            feats.append('U17:%s/%s' % (sent[idx][1], sent[idx+1][1]))\n",
    "            if idx < sent_len-2:\n",
    "                feats.append('U04:%s' % sent[idx+2][0])\n",
    "                feats.append('U14:%s' % sent[idx+2][1])\n",
    "                feats.append('U18:%s/%s' % (sent[idx+1][1],sent[idx+2][1]))\n",
    "                feats.append('U22:%s/%s/%s' % (sent[idx][1],sent[idx+1][1],sent[idx+2][1]))\n",
    "            if idx > 0:\n",
    "                feats.append('U21:%s/%s/%s' % (sent[idx-1][1],sent[idx][1],sent[idx+1][1]))\n",
    "        if idx > 0:\n",
    "            feats.append('U01:%s' % sent[idx-1][0])\n",
    "            feats.append('U11:%s' % sent[idx-1][1])\n",
    "            feats.append('U05:%s/%s' % (sent[idx-1][0],sent[idx][0]))\n",
    "            feats.append('U16:%s/%s' % (sent[idx-1][1],sent[idx][1]))        \n",
    "            if idx > 1:\n",
    "                feats.append('U00:%s' % sent[idx-2][0])\n",
    "                feats.append('U10:%s' % sent[idx-2][1])\n",
    "                feats.append('U15:%s/%s' % (sent[idx-2][1],sent[idx-1][1]))\n",
    "                feats.append('U20:%s/%s/%s' % (sent[idx-2][1],sent[idx-1][1],sent[idx][1]))\n",
    "        return feats\n",
    "    \n",
    "    def add(self, prev_y,y,sent,idx):\n",
    "        for feature_string in self.get_word_feats(sent, idx):\n",
    "            if feature_string in self.feature_dic.keys():\n",
    "                if (prev_y, y) in self.feature_dic[feature_string].keys():\n",
    "                    self.empirical_counts[self.feature_dic[feature_string][(prev_y, y)]] += 1\n",
    "                else:\n",
    "                    feature_id = self.num_features\n",
    "                    self.feature_dic[feature_string][(prev_y, y)] = feature_id\n",
    "                    self.empirical_counts[feature_id] += 1\n",
    "                    self.num_features += 1\n",
    "                if (-1, y) in self.feature_dic[feature_string].keys():\n",
    "                    self.empirical_counts[self.feature_dic[feature_string][(-1, y)]] += 1\n",
    "                else:\n",
    "                    feature_id = self.num_features\n",
    "                    self.feature_dic[feature_string][(-1, y)] = feature_id\n",
    "                    self.empirical_counts[feature_id] += 1\n",
    "                    self.num_features += 1\n",
    "            else:\n",
    "                self.feature_dic[feature_string] = dict()\n",
    "                # Bigram feature\n",
    "                feature_id = self.num_features\n",
    "                self.feature_dic[feature_string][(prev_y, y)] = feature_id\n",
    "                self.empirical_counts[feature_id] += 1\n",
    "                self.num_features += 1\n",
    "                # Unigram feature\n",
    "                feature_id = self.num_features\n",
    "                self.feature_dic[feature_string][(-1, y)] = feature_id\n",
    "                self.empirical_counts[feature_id] += 1\n",
    "                self.num_features += 1\n",
    "    \n",
    "    def scan(self, data):\n",
    "        for sent in data:\n",
    "            prev_y = START_LABEL_IDX\n",
    "            for idx in range(len(sent)):\n",
    "                try:\n",
    "                    y_idx = self.label_dic(sent[idx][-1])\n",
    "                except KeyError:\n",
    "                    y_idx = len(self.label_dic)\n",
    "                    self.label_dic[sent[idx][-1]] = y_idx\n",
    "                    self.label_array.append(sent[idx][-1])\n",
    "                self.add(prev_y, y, sent, idx)\n",
    "                prev_y = y\n",
    "                \n",
    "        \n",
    "    def _generate_all_feats_labels(self):\n",
    "        \n",
    "        for s in self.X:\n",
    "            feats_list, labels_list,_,_ = self.get_sentence_feats_labels(s)\n",
    "            self.feats.update(feats_list)\n",
    "            self.labels.update(labels_list)\n",
    "            \n",
    "    def get_dataset_feats_labels():\n",
    "        return self.feats, self.labels\n",
    "    \n",
    "    def feats2idx_func(self):\n",
    "        for idx,f in enumerate(self.feats.keys()):\n",
    "            self.feats2idx[f] = idx\n",
    "            \n",
    "    def labels2idx_func(self):\n",
    "        labels = self.labels.keys()\n",
    "        \n",
    "        for idx, lbl in enumerate(labels):\n",
    "            self.labels2idx[lbl] = idx\n",
    "            \n",
    "        length = len(self.labels2idx.keys())\n",
    "        for idx, lbl in enumerate(labels):\n",
    "            for idxx, lbll in enumerate(labels):\n",
    "                self.labels2idx[lbl + SEP2 + lbll] = length+ idx*length + idxx\n",
    "    \n",
    "        length = len(self.labels2idx.keys())\n",
    "        for idx, lbl in enumerate(labels):\n",
    "            self.labels2idx[START_LABEL + SEP2 + lbl] = length + 2*idx\n",
    "            self.labels2idx[lbl + SEP2 + STOP_LABEL] = length + 2*idx + 1                # include STOP_LABEL\n",
    "    \n",
    "    def featfunc_size(self):    \n",
    "        self.feats_size, self.labels_size = len(self.feats.keys()), len(self.labels.keys())\n",
    "        return self.feats_size, self.labels_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearChainCRF():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.Feat = Feature(data)\n",
    "        self.featfunc_matrix = None\n",
    "        self.feats2idx=None\n",
    "        self.labels2idx = None\n",
    "        self.valid_featfunc_in_data = None\n",
    "        self.labels_size, self.feats_size = 0, 0\n",
    "        self.labels = None\n",
    "        \n",
    "    def init_params(self):\n",
    "        self.Feat._generate_all_feats_labels()\n",
    "        self.Feat.feats2idx_func()\n",
    "        self.feats2idx = self.Feat.feats2idx\n",
    "        self.Feat.labels2idx_func()                                                     # START_LABEL, included\n",
    "        self.labels2idx = self.Feat.labels2idx\n",
    "        self.labels = list(self.Feat.labels.keys())                                     # START_LABEL,  not included\n",
    "        self.labels2idx_formal = {l:i for i,l in enumerate(self.labels)}\n",
    "        self.feats_size, self.labels_size = self.Feat.featfunc_size()\n",
    "        self.featfunc_matrix = np.zeros([len(self.feats2idx),len(self.labels2idx)])\n",
    "        \n",
    "    def empirical_expectation(self, batch_data):\n",
    "        valid_funcs = Counter()\n",
    "        emp_exp = 0\n",
    "        for sent in batch_data:\n",
    "            _,_,valid_func,_ = self.Feat.get_sentence_feats_labels(sent)\n",
    "            valid_funcs.update(valid_func)\n",
    "        \n",
    "        for vf,c in valid_funcs.items():\n",
    "            feat, lbl = vf.split(SEP1)\n",
    "            emp_exp += self.featfunc_matrix[self.feats2idx[feat],self.labels2idx[lbl]] * c\n",
    "        \n",
    "        return emp_exp,valid_funcs\n",
    "    \n",
    "    def _forward_backward(self, sent):\n",
    "        alpha0 = np.zeros(self.labels_size)\n",
    "        beta0 = np.zeros(self.labels_size)\n",
    "        alpha0[0],beta0[0] = 1,1\n",
    "        \n",
    "        sent_length = len(sent)\n",
    "        \n",
    "        sent_feats,_,_, featfunc_in_sent_position = self.Feat.get_sentence_feats_labels(sent)\n",
    "        # M_n(y_{n-1},y{n}|x)\n",
    "        M = []\n",
    "        for n in range(sent_length+1):\n",
    "            M_n = np.zeros([self.labels_size, self.labels_size])\n",
    "            if n==0:\n",
    "                feats_idx = [self.feats2idx[sent_feats[j]] for j in range(len(sent_feats))]\n",
    "                for i in range(self.labels_size):\n",
    "                    labels_idx = self.labels2idx[START_LABEL + SEP2 + self.labels[i]]\n",
    "                    M_n[0,i] += np.exp(np.sum(self.featfunc_matrix[feats_idx,labels_idx]))\n",
    "                M.append(M_n)\n",
    "            elif n<sent_length:\n",
    "                feats_idx = [self.feats2idx[sent_feats[j]] for j in range(len(sent_feats))]\n",
    "                for k in range(self.labels_size):\n",
    "                    for i in range(self.labels_size):\n",
    "                        labels_idx = self.labels2idx[self.labels[k]+SEP2+self.labels[i]]\n",
    "                        M_n[k,i] += np.exp(np.sum(self.featfunc_matrix[feats_idx,labels_idx]))\n",
    "                M.append(M_n)\n",
    "            else:\n",
    "                feats_idx = [self.feats2idx[sent_feats[j]] for j in range(len(sent_feats))]\n",
    "                for k in range(self.labels_size):\n",
    "                    labels_idx = self.labels2idx[self.labels[k]+SEP2+ STOP_LABEL]\n",
    "                    M_n[k,0] += np.exp(np.sum(self.featfunc_matrix[feats_idx,labels_idx]))\n",
    "                M.append(M_n)\n",
    "                \n",
    "        alphas, betas = [alpha0],[beta0]\n",
    "        prev_alpha, cur_beta = alpha0, beta0\n",
    "        Z = np.eye(self.labels_size)\n",
    "        \n",
    "        for n in range(sent_length+1):\n",
    "            cur_alpha = prev_alpha.dot(M[n])\n",
    "            alphas.append(cur_alpha)\n",
    "            prev_alpha = alphas[-1]\n",
    "            Z = Z.dot(M[n])\n",
    "        for n in range(sent_length,-1,-1):   \n",
    "            prev_beta = M[n].dot(cur_beta)\n",
    "            betas.insert(0,prev_beta)\n",
    "            cur_beta = betas[0]\n",
    "\n",
    "        \n",
    "        norm_factor = Z[0,0]\n",
    "        \n",
    "        return M, np.array(alphas), np.array(betas), norm_factor, featfunc_in_sent_position\n",
    "        \n",
    "    def train(self, num_iters, batch_size, learning_rate, reg=10, do_reg=True):\n",
    "        data_size = len(self.data)\n",
    "        batch_size=data_size\n",
    "        \n",
    "        for i in range(num_iters):\n",
    "            for b in range(0, data_size, batch_size):\n",
    "                batch_data = self.data[b:b+batch_size]\n",
    "                emp_exp, valid_funcs = self.empirical_expectation(batch_data)\n",
    "                norm = 0\n",
    "                gradients = np.zeros_like(self.featfunc_matrix)\n",
    "                for sent in batch_data:\n",
    "                    \n",
    "                    M,alpha,beta,Z, featfunc_in_sent_position = self._forward_backward(sent)\n",
    "                    norm += np.log(Z)\n",
    "                    \n",
    "                    for f,pos in featfunc_in_sent_position.items():\n",
    "                        if len(pos) > 0:\n",
    "                            feat, label = f.split(SEP1)\n",
    "                            lbl = label.split(SEP2)\n",
    "                            fidx = self.feats2idx[feat]\n",
    "                            labels_idx = self.labels2idx[label]\n",
    "                            if len(lbl) == 1:\n",
    "                                for p in pos:\n",
    "                                    gradients[fidx,labels_idx] -= alpha[p][labels_idx]*beta[p][labels_idx]/Z\n",
    "                            if len(lbl) == 2:\n",
    "                                lbl1, lbl2 = lbl[0],lbl[1]\n",
    "                                if lbl1 == START_LABEL: # can only at p=0\n",
    "                                    lbl2_idx = self.labels2idx_formal[lbl2]\n",
    "                                    gradients[fidx, labels_idx] -= alpha[0][0]*M[0][0,lbl2_idx]*beta[1][lbl2_idx]/Z\n",
    "                                elif lbl2 == STOP_LABEL:\n",
    "                                    lbl1_idx = self.labels2idx_formal[lbl1]\n",
    "                                    gradients[fidx, labels_idx] -= alpha[pos[0]][lbl1_idx]*M[pos[0]][lbl1_idx,0]*beta[pos[0]+1][0]/Z \n",
    "                                else:\n",
    "                                    lbl1_idx = self.labels2idx_formal[lbl1]\n",
    "                                    lbl2_idx = self.labels2idx_formal[lbl2]\n",
    "                                    for p in pos:\n",
    "                                        gradients[fidx,labels_idx] -= alpha[p][lbl1_idx]*M[p][lbl1_idx,lbl2_idx]*beta[p+1][lbl2_idx]/Z\n",
    "                \n",
    "                log_likelihood = -(emp_exp - norm) \n",
    "                \n",
    "                if do_reg:\n",
    "                    log_likelihood -= np.sum(self.featfunc_matrix**2)/(2*reg)\n",
    "                    gradients -= self.featfunc_matrix/reg\n",
    "                    \n",
    "                for f,c in valid_funcs.items():\n",
    "                    feat, label = f.split(SEP1)\n",
    "                    fidx,lidx = self.feats2idx[feat],self.labels2idx[label]\n",
    "                    gradients[fidx,lidx] += c\n",
    "                    \n",
    "                #update\n",
    "                self.featfunc_matrix += learning_rate * gradients\n",
    "                print(np.nonzero(self.featfunc_matrix)[0].size)\n",
    "                print('log likelihood:', log_likelihood)\n",
    "                print('-'*20)\n",
    "    def test(self):\n",
    "        pass\n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31233\n",
      "log likelihood: 5003.65269695053\n",
      "--------------------\n",
      "31299\n",
      "log likelihood: 4923.562969063472\n",
      "--------------------\n",
      "31306\n",
      "log likelihood: 4856.615751029051\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-d2ffa5a76575>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearChainCRF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdo_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-dde8c9345f07>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, num_iters, batch_size, learning_rate, reg, do_reg)\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                     \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatfunc_in_sent_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                     \u001b[0mnorm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-dde8c9345f07>\u001b[0m in \u001b[0;36m_forward_backward\u001b[1;34m(self, sent)\u001b[0m\n\u001b[0;32m     57\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                         \u001b[0mlabels_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mSEP2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                         \u001b[0mM_n\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatfunc_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeats_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m                 \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crf = LinearChainCRF(train_data)\n",
    "crf.init_params()\n",
    "crf.train(30,32,1e-4,10,do_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-96bf640b1d20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'data\\base_modell'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Circular reference detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "b=np.ones((3,3))\n",
    "a={'s':b}\n",
    "f = open(r'data\\base_modell','w')\n",
    "json.dump(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package json:\n",
      "\n",
      "NAME\n",
      "    json\n",
      "\n",
      "DESCRIPTION\n",
      "    JSON (JavaScript Object Notation) <http://json.org> is a subset of\n",
      "    JavaScript syntax (ECMA-262 3rd edition) used as a lightweight data\n",
      "    interchange format.\n",
      "    \n",
      "    :mod:`json` exposes an API familiar to users of the standard library\n",
      "    :mod:`marshal` and :mod:`pickle` modules.  It is derived from a\n",
      "    version of the externally maintained simplejson library.\n",
      "    \n",
      "    Encoding basic Python object hierarchies::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])\n",
      "        '[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'\n",
      "        >>> print(json.dumps(\"\\\"foo\\bar\"))\n",
      "        \"\\\"foo\\bar\"\n",
      "        >>> print(json.dumps('\\u1234'))\n",
      "        \"\\u1234\"\n",
      "        >>> print(json.dumps('\\\\'))\n",
      "        \"\\\\\"\n",
      "        >>> print(json.dumps({\"c\": 0, \"b\": 0, \"a\": 0}, sort_keys=True))\n",
      "        {\"a\": 0, \"b\": 0, \"c\": 0}\n",
      "        >>> from io import StringIO\n",
      "        >>> io = StringIO()\n",
      "        >>> json.dump(['streaming API'], io)\n",
      "        >>> io.getvalue()\n",
      "        '[\"streaming API\"]'\n",
      "    \n",
      "    Compact encoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> mydict = {'4': 5, '6': 7}\n",
      "        >>> json.dumps([1,2,3,mydict], separators=(',', ':'))\n",
      "        '[1,2,3,{\"4\":5,\"6\":7}]'\n",
      "    \n",
      "    Pretty printing::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> print(json.dumps({'4': 5, '6': 7}, sort_keys=True, indent=4))\n",
      "        {\n",
      "            \"4\": 5,\n",
      "            \"6\": 7\n",
      "        }\n",
      "    \n",
      "    Decoding JSON::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> obj = ['foo', {'bar': ['baz', None, 1.0, 2]}]\n",
      "        >>> json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]') == obj\n",
      "        True\n",
      "        >>> json.loads('\"\\\\\"foo\\\\bar\"') == '\"foo\\x08ar'\n",
      "        True\n",
      "        >>> from io import StringIO\n",
      "        >>> io = StringIO('[\"streaming API\"]')\n",
      "        >>> json.load(io)[0] == 'streaming API'\n",
      "        True\n",
      "    \n",
      "    Specializing JSON object decoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> def as_complex(dct):\n",
      "        ...     if '__complex__' in dct:\n",
      "        ...         return complex(dct['real'], dct['imag'])\n",
      "        ...     return dct\n",
      "        ...\n",
      "        >>> json.loads('{\"__complex__\": true, \"real\": 1, \"imag\": 2}',\n",
      "        ...     object_hook=as_complex)\n",
      "        (1+2j)\n",
      "        >>> from decimal import Decimal\n",
      "        >>> json.loads('1.1', parse_float=Decimal) == Decimal('1.1')\n",
      "        True\n",
      "    \n",
      "    Specializing JSON object encoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> def encode_complex(obj):\n",
      "        ...     if isinstance(obj, complex):\n",
      "        ...         return [obj.real, obj.imag]\n",
      "        ...     raise TypeError(f'Object of type {obj.__class__.__name__} '\n",
      "        ...                     f'is not JSON serializable')\n",
      "        ...\n",
      "        >>> json.dumps(2 + 1j, default=encode_complex)\n",
      "        '[2.0, 1.0]'\n",
      "        >>> json.JSONEncoder(default=encode_complex).encode(2 + 1j)\n",
      "        '[2.0, 1.0]'\n",
      "        >>> ''.join(json.JSONEncoder(default=encode_complex).iterencode(2 + 1j))\n",
      "        '[2.0, 1.0]'\n",
      "    \n",
      "    \n",
      "    Using json.tool from the shell to validate and pretty-print::\n",
      "    \n",
      "        $ echo '{\"json\":\"obj\"}' | python -m json.tool\n",
      "        {\n",
      "            \"json\": \"obj\"\n",
      "        }\n",
      "        $ echo '{ 1.2:3.4}' | python -m json.tool\n",
      "        Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    decoder\n",
      "    encoder\n",
      "    scanner\n",
      "    tool\n",
      "\n",
      "CLASSES\n",
      "    builtins.ValueError(builtins.Exception)\n",
      "        json.decoder.JSONDecodeError\n",
      "    builtins.object\n",
      "        json.decoder.JSONDecoder\n",
      "        json.encoder.JSONEncoder\n",
      "    \n",
      "    class JSONDecodeError(builtins.ValueError)\n",
      "     |  JSONDecodeError(msg, doc, pos)\n",
      "     |  \n",
      "     |  Subclass of ValueError with the following additional properties:\n",
      "     |  \n",
      "     |  msg: The unformatted error message\n",
      "     |  doc: The JSON document being parsed\n",
      "     |  pos: The start index of doc where parsing failed\n",
      "     |  lineno: The line corresponding to pos\n",
      "     |  colno: The column corresponding to pos\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JSONDecodeError\n",
      "     |      builtins.ValueError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg, doc, pos)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.ValueError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class JSONDecoder(builtins.object)\n",
      "     |  JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)\n",
      "     |  \n",
      "     |  Simple JSON <http://json.org> decoder\n",
      "     |  \n",
      "     |  Performs the following translations in decoding by default:\n",
      "     |  \n",
      "     |  +---------------+-------------------+\n",
      "     |  | JSON          | Python            |\n",
      "     |  +===============+===================+\n",
      "     |  | object        | dict              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | array         | list              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | string        | str               |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | number (int)  | int               |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | number (real) | float             |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | true          | True              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | false         | False             |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | null          | None              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  \n",
      "     |  It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as\n",
      "     |  their corresponding ``float`` values, which is outside the JSON spec.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)\n",
      "     |      ``object_hook``, if specified, will be called with the result\n",
      "     |      of every JSON object decoded and its return value will be used in\n",
      "     |      place of the given ``dict``.  This can be used to provide custom\n",
      "     |      deserializations (e.g. to support JSON-RPC class hinting).\n",
      "     |      \n",
      "     |      ``object_pairs_hook``, if specified will be called with the result of\n",
      "     |      every JSON object decoded with an ordered list of pairs.  The return\n",
      "     |      value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "     |      This feature can be used to implement custom decoders.\n",
      "     |      If ``object_hook`` is also defined, the ``object_pairs_hook`` takes\n",
      "     |      priority.\n",
      "     |      \n",
      "     |      ``parse_float``, if specified, will be called with the string\n",
      "     |      of every JSON float to be decoded. By default this is equivalent to\n",
      "     |      float(num_str). This can be used to use another datatype or parser\n",
      "     |      for JSON floats (e.g. decimal.Decimal).\n",
      "     |      \n",
      "     |      ``parse_int``, if specified, will be called with the string\n",
      "     |      of every JSON int to be decoded. By default this is equivalent to\n",
      "     |      int(num_str). This can be used to use another datatype or parser\n",
      "     |      for JSON integers (e.g. float).\n",
      "     |      \n",
      "     |      ``parse_constant``, if specified, will be called with one of the\n",
      "     |      following strings: -Infinity, Infinity, NaN.\n",
      "     |      This can be used to raise an exception if invalid JSON numbers\n",
      "     |      are encountered.\n",
      "     |      \n",
      "     |      If ``strict`` is false (true is the default), then control\n",
      "     |      characters will be allowed inside strings.  Control characters in\n",
      "     |      this context are those with character codes in the 0-31 range,\n",
      "     |      including ``'\\t'`` (tab), ``'\\n'``, ``'\\r'`` and ``'\\0'``.\n",
      "     |  \n",
      "     |  decode(self, s, _w=<built-in method match of re.Pattern object at 0x000001E57EFAA270>)\n",
      "     |      Return the Python representation of ``s`` (a ``str`` instance\n",
      "     |      containing a JSON document).\n",
      "     |  \n",
      "     |  raw_decode(self, s, idx=0)\n",
      "     |      Decode a JSON document from ``s`` (a ``str`` beginning with\n",
      "     |      a JSON document) and return a 2-tuple of the Python\n",
      "     |      representation and the index in ``s`` where the document ended.\n",
      "     |      \n",
      "     |      This can be used to decode a JSON document from a string that may\n",
      "     |      have extraneous data at the end.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class JSONEncoder(builtins.object)\n",
      "     |  JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)\n",
      "     |  \n",
      "     |  Extensible JSON <http://json.org> encoder for Python data structures.\n",
      "     |  \n",
      "     |  Supports the following objects and types by default:\n",
      "     |  \n",
      "     |  +-------------------+---------------+\n",
      "     |  | Python            | JSON          |\n",
      "     |  +===================+===============+\n",
      "     |  | dict              | object        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | list, tuple       | array         |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | str               | string        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | int, float        | number        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | True              | true          |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | False             | false         |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | None              | null          |\n",
      "     |  +-------------------+---------------+\n",
      "     |  \n",
      "     |  To extend this to recognize other objects, subclass and implement a\n",
      "     |  ``.default()`` method with another method that returns a serializable\n",
      "     |  object for ``o`` if possible, otherwise it should call the superclass\n",
      "     |  implementation (to raise ``TypeError``).\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)\n",
      "     |      Constructor for JSONEncoder, with sensible defaults.\n",
      "     |      \n",
      "     |      If skipkeys is false, then it is a TypeError to attempt\n",
      "     |      encoding of keys that are not str, int, float or None.  If\n",
      "     |      skipkeys is True, such items are simply skipped.\n",
      "     |      \n",
      "     |      If ensure_ascii is true, the output is guaranteed to be str\n",
      "     |      objects with all incoming non-ASCII characters escaped.  If\n",
      "     |      ensure_ascii is false, the output can contain non-ASCII characters.\n",
      "     |      \n",
      "     |      If check_circular is true, then lists, dicts, and custom encoded\n",
      "     |      objects will be checked for circular references during encoding to\n",
      "     |      prevent an infinite recursion (which would cause an OverflowError).\n",
      "     |      Otherwise, no such check takes place.\n",
      "     |      \n",
      "     |      If allow_nan is true, then NaN, Infinity, and -Infinity will be\n",
      "     |      encoded as such.  This behavior is not JSON specification compliant,\n",
      "     |      but is consistent with most JavaScript based encoders and decoders.\n",
      "     |      Otherwise, it will be a ValueError to encode such floats.\n",
      "     |      \n",
      "     |      If sort_keys is true, then the output of dictionaries will be\n",
      "     |      sorted by key; this is useful for regression tests to ensure\n",
      "     |      that JSON serializations can be compared on a day-to-day basis.\n",
      "     |      \n",
      "     |      If indent is a non-negative integer, then JSON array\n",
      "     |      elements and object members will be pretty-printed with that\n",
      "     |      indent level.  An indent level of 0 will only insert newlines.\n",
      "     |      None is the most compact representation.\n",
      "     |      \n",
      "     |      If specified, separators should be an (item_separator, key_separator)\n",
      "     |      tuple.  The default is (', ', ': ') if *indent* is ``None`` and\n",
      "     |      (',', ': ') otherwise.  To get the most compact JSON representation,\n",
      "     |      you should specify (',', ':') to eliminate whitespace.\n",
      "     |      \n",
      "     |      If specified, default is a function that gets called for objects\n",
      "     |      that can't otherwise be serialized.  It should return a JSON encodable\n",
      "     |      version of the object or raise a ``TypeError``.\n",
      "     |  \n",
      "     |  default(self, o)\n",
      "     |      Implement this method in a subclass such that it returns\n",
      "     |      a serializable object for ``o``, or calls the base implementation\n",
      "     |      (to raise a ``TypeError``).\n",
      "     |      \n",
      "     |      For example, to support arbitrary iterators, you could\n",
      "     |      implement default like this::\n",
      "     |      \n",
      "     |          def default(self, o):\n",
      "     |              try:\n",
      "     |                  iterable = iter(o)\n",
      "     |              except TypeError:\n",
      "     |                  pass\n",
      "     |              else:\n",
      "     |                  return list(iterable)\n",
      "     |              # Let the base class default method raise the TypeError\n",
      "     |              return JSONEncoder.default(self, o)\n",
      "     |  \n",
      "     |  encode(self, o)\n",
      "     |      Return a JSON string representation of a Python data structure.\n",
      "     |      \n",
      "     |      >>> from json.encoder import JSONEncoder\n",
      "     |      >>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n",
      "     |      '{\"foo\": [\"bar\", \"baz\"]}'\n",
      "     |  \n",
      "     |  iterencode(self, o, _one_shot=False)\n",
      "     |      Encode the given object and yield each string\n",
      "     |      representation as available.\n",
      "     |      \n",
      "     |      For example::\n",
      "     |      \n",
      "     |          for chunk in JSONEncoder().iterencode(bigobject):\n",
      "     |              mysocket.write(chunk)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  item_separator = ', '\n",
      "     |  \n",
      "     |  key_separator = ': '\n",
      "\n",
      "FUNCTIONS\n",
      "    dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "        Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
      "        ``.write()``-supporting file-like object).\n",
      "        \n",
      "        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "        instead of raising a ``TypeError``.\n",
      "        \n",
      "        If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
      "        contain non-ASCII characters if they appear in strings contained in\n",
      "        ``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
      "        \n",
      "        If ``check_circular`` is false, then the circular reference check\n",
      "        for container types will be skipped and a circular reference will\n",
      "        result in an ``OverflowError`` (or worse).\n",
      "        \n",
      "        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
      "        in strict compliance of the JSON specification, instead of using the\n",
      "        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "        \n",
      "        If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "        object members will be pretty-printed with that indent level. An indent\n",
      "        level of 0 will only insert newlines. ``None`` is the most compact\n",
      "        representation.\n",
      "        \n",
      "        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "        you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "        \n",
      "        ``default(obj)`` is a function that should return a serializable version\n",
      "        of obj or raise TypeError. The default simply raises TypeError.\n",
      "        \n",
      "        If *sort_keys* is true (default: ``False``), then the output of\n",
      "        dictionaries will be sorted by key.\n",
      "        \n",
      "        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "        ``.default()`` method to serialize additional types), specify it with\n",
      "        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "    \n",
      "    dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "        Serialize ``obj`` to a JSON formatted ``str``.\n",
      "        \n",
      "        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "        instead of raising a ``TypeError``.\n",
      "        \n",
      "        If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n",
      "        characters if they appear in strings contained in ``obj``. Otherwise, all\n",
      "        such characters are escaped in JSON strings.\n",
      "        \n",
      "        If ``check_circular`` is false, then the circular reference check\n",
      "        for container types will be skipped and a circular reference will\n",
      "        result in an ``OverflowError`` (or worse).\n",
      "        \n",
      "        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n",
      "        strict compliance of the JSON specification, instead of using the\n",
      "        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "        \n",
      "        If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "        object members will be pretty-printed with that indent level. An indent\n",
      "        level of 0 will only insert newlines. ``None`` is the most compact\n",
      "        representation.\n",
      "        \n",
      "        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "        you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "        \n",
      "        ``default(obj)`` is a function that should return a serializable version\n",
      "        of obj or raise TypeError. The default simply raises TypeError.\n",
      "        \n",
      "        If *sort_keys* is true (default: ``False``), then the output of\n",
      "        dictionaries will be sorted by key.\n",
      "        \n",
      "        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "        ``.default()`` method to serialize additional types), specify it with\n",
      "        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "    \n",
      "    load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "        Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n",
      "        a JSON document) to a Python object.\n",
      "        \n",
      "        ``object_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decode (a ``dict``). The return value of\n",
      "        ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "        \n",
      "        ``object_pairs_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decoded with an ordered list of pairs.  The\n",
      "        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "        This feature can be used to implement custom decoders.  If ``object_hook``\n",
      "        is also defined, the ``object_pairs_hook`` takes priority.\n",
      "        \n",
      "        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "        kwarg; otherwise ``JSONDecoder`` is used.\n",
      "    \n",
      "    loads(s, *, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "        Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance\n",
      "        containing a JSON document) to a Python object.\n",
      "        \n",
      "        ``object_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decode (a ``dict``). The return value of\n",
      "        ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "        \n",
      "        ``object_pairs_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decoded with an ordered list of pairs.  The\n",
      "        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "        This feature can be used to implement custom decoders.  If ``object_hook``\n",
      "        is also defined, the ``object_pairs_hook`` takes priority.\n",
      "        \n",
      "        ``parse_float``, if specified, will be called with the string\n",
      "        of every JSON float to be decoded. By default this is equivalent to\n",
      "        float(num_str). This can be used to use another datatype or parser\n",
      "        for JSON floats (e.g. decimal.Decimal).\n",
      "        \n",
      "        ``parse_int``, if specified, will be called with the string\n",
      "        of every JSON int to be decoded. By default this is equivalent to\n",
      "        int(num_str). This can be used to use another datatype or parser\n",
      "        for JSON integers (e.g. float).\n",
      "        \n",
      "        ``parse_constant``, if specified, will be called with one of the\n",
      "        following strings: -Infinity, Infinity, NaN.\n",
      "        This can be used to raise an exception if invalid JSON numbers\n",
      "        are encountered.\n",
      "        \n",
      "        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "        kwarg; otherwise ``JSONDecoder`` is used.\n",
      "        \n",
      "        The ``encoding`` argument is ignored and deprecated.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['dump', 'dumps', 'load', 'loads', 'JSONDecoder', 'JSONDecod...\n",
      "\n",
      "VERSION\n",
      "    2.0.9\n",
      "\n",
      "AUTHOR\n",
      "    Bob Ippolito <bob@redivi.com>\n",
      "\n",
      "FILE\n",
      "    e:\\anaconda\\lib\\json\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
