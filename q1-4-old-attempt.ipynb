{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path('./dataset/')\n",
    "AL = DATA_FOLDER/'AL'\n",
    "AL_train = AL/'train'\n",
    "AL_dev_x = AL/'dev.in'\n",
    "AL_dev_y = AL/'dev.out'\n",
    "AL_out_2 = AL/'dev.p2.out'\n",
    "AL_out_3 = AL/'dev.p3.out'\n",
    "AL_out_4 = AL/'dev.p4.out'\n",
    "\n",
    "EN = DATA_FOLDER/'EN'\n",
    "EN_train = EN/'train'\n",
    "EN_dev_x = EN/'dev.in'\n",
    "EN_dev_y = EN/'dev.out'\n",
    "EN_out_2 = EN/'dev.p2.out'\n",
    "EN_out_3 = EN/'dev.p3.out'\n",
    "EN_out_4 = EN/'dev.p4.out'\n",
    "\n",
    "CN = DATA_FOLDER/'CN'\n",
    "CN_train = CN/'train'\n",
    "CN_dev_x = CN/'dev.in'\n",
    "CN_dev_y = CN/'dev.out'\n",
    "CN_out_2 = CN/'dev.p2.out'\n",
    "CN_out_3 = CN/'dev.p3.out'\n",
    "\n",
    "SG = DATA_FOLDER/'SG'\n",
    "SG_train = SG/'train'\n",
    "SG_dev_x = SG/'dev.in'\n",
    "SG_dev_y = SG/'dev.out'\n",
    "SG_out_2 = SG/'dev.p2.out'\n",
    "SG_out_3 = SG/'dev.p3.out'\n",
    "\n",
    "\n",
    "EVAL_script = './EvalScript/evalResult.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    x, y = [], []\n",
    "    temp_x, temp_y = [], []\n",
    "    for l in lines:\n",
    "        if len(l) == 1:\n",
    "            assert(len(temp_x) == len(temp_y))\n",
    "            x.append(temp_x)\n",
    "            y.append(temp_y)\n",
    "            temp_x, temp_y = [], []\n",
    "            continue\n",
    "        xx, yy = l.split()\n",
    "        temp_x.append(xx)\n",
    "        temp_y.append(yy)\n",
    "    if len(temp_x) != 0:\n",
    "        x.append(temp_x)\n",
    "        y.append(temp_y)\n",
    "    assert(len(x) == len(y))\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def get_test_data(filename, word2index):\n",
    "    \"\"\"Return:\n",
    "                x: nested list of string\n",
    "                x_int: nested list of integer\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    x = []\n",
    "    temp_x = []\n",
    "    for l in lines:\n",
    "        if len(l.strip()) == 0:\n",
    "            x.append(temp_x)\n",
    "            temp_x = []\n",
    "            continue\n",
    "        xx = l.split()\n",
    "        temp_x.append(xx[0])\n",
    "    if len(temp_x) != 0:\n",
    "        x.append(temp_x)\n",
    "    x_int = [[word2index[oo] for oo in o] for o in x ]\n",
    "    return x, x_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = get_train_data(AL_train)\n",
    "vocab = list(set([oo for o in words for oo in o]))\n",
    "tags = list(set([oo for o in labels for oo in o])) + ['SOS', 'EOS']\n",
    "word2index = {o:i for i,o in enumerate(vocab)}\n",
    "index2word = {i:o for i,o in enumerate(vocab)}\n",
    "tag2index = {o:i for i,o in enumerate(tags)}\n",
    "x = [[word2index[oo] for oo in o] for o in words]\n",
    "y = [[tag2index[oo] for oo in o] for o in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1 Emission features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission(x, y, vocab, tags):\n",
    "    emission = np.zeros((len(vocab), len(tags)))\n",
    "    flat_y = [oo for o in y for oo in o]\n",
    "    flat_x = [oo for o in x for oo in o]\n",
    "    for xx, yy in zip(flat_x,flat_y):\n",
    "        emission[xx, yy] += 1\n",
    "    \n",
    "    y_count = np.zeros(len(tags))\n",
    "    for yy in flat_y:\n",
    "        y_count[yy] += 1\n",
    "    emission = emission/ y_count[None, :]\n",
    "    np.nan_to_num(emission, 0)\n",
    "    return emission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Adding smoothing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "vocab_count = Counter([oo for o in words for oo in o])\n",
    "vocab = [o for o, v in dict(vocab_count).items() if v>=3] + ['#UNK#']\n",
    "word2index = defaultdict(int)\n",
    "for i,o in enumerate(vocab): word2index[o] = i+1\n",
    "x = [ [word2index[oo] for oo in o] for o in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding(x, emission_matrix):\n",
    "    \"\"\"emission matrix: (vocab_size, tag_size)\n",
    "    x: converted to integer arrays\"\"\"\n",
    "    return emission_matrix[x].argmax(axis=1)\n",
    "\n",
    "def batch_decoding(output_filename, dev_x_filename, word2index, emission_matrix, tags):\n",
    "    with open(output_filename, 'w') as f:\n",
    "        words, dev_x = get_test_data(dev_x_filename, word2index)\n",
    "        for ws,o in zip(words, dev_x):\n",
    "            path = decoding(o, emission_matrix)\n",
    "            for w, p in zip(ws, path):\n",
    "                f.write(w + ' ' + tags[p] + '\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab everythings together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_file, output_filename, dev_x_filename):\n",
    "    # read data\n",
    "    words, labels = get_train_data(train_file)\n",
    "    # create vocab\n",
    "    tags = list(set([oo for o in labels for oo in o])) + ['SOS', 'EOS']\n",
    "    tag2index = {o:i for i,o in enumerate(tags)}\n",
    "    vocab_count = Counter([oo for o in words for oo in o])\n",
    "    vocab = [o for o, v in dict(vocab_count).items() if v>=3] + ['#UNK#']\n",
    "    word2index = defaultdict(int)\n",
    "    for i,o in enumerate(vocab): word2index[o] = i+1\n",
    "    # text to int\n",
    "    x = [[word2index[oo] for oo in o] for o in words]\n",
    "    y = [[tag2index[oo] for oo in o] for o in labels]\n",
    "    # training\n",
    "    emission_matrix = emission(x, y, vocab, tags)\n",
    "    # decoding\n",
    "    batch_decoding(output_filename, dev_x_filename, word2index, emission_matrix, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 8408\r\n",
      "#Entity in prediction: 19484\r\n",
      "\r\n",
      "#Correct Entity : 2898\r\n",
      "Entity  precision: 0.1487\r\n",
      "Entity  recall: 0.3447\r\n",
      "Entity  F: 0.2078\r\n",
      "\r\n",
      "#Correct Sentiment : 2457\r\n",
      "Sentiment  precision: 0.1261\r\n",
      "Sentiment  recall: 0.2922\r\n",
      "Sentiment  F: 0.1762\r\n"
     ]
    }
   ],
   "source": [
    "main(AL_train, AL_out_2, AL_dev_x)\n",
    "! python {EVAL_script} {AL_dev_y} {AL_out_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 4537\r\n",
      "#Entity in prediction: 18451\r\n",
      "\r\n",
      "#Correct Entity : 2632\r\n",
      "Entity  precision: 0.1426\r\n",
      "Entity  recall: 0.5801\r\n",
      "Entity  F: 0.2290\r\n",
      "\r\n",
      "#Correct Sentiment : 1239\r\n",
      "Sentiment  precision: 0.0672\r\n",
      "Sentiment  recall: 0.2731\r\n",
      "Sentiment  F: 0.1078\r\n"
     ]
    }
   ],
   "source": [
    "main(SG_train, SG_out_2, SG_dev_x)\n",
    "! python {EVAL_script} {SG_dev_y} {SG_out_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 13179\r\n",
      "#Entity in prediction: 19406\r\n",
      "\r\n",
      "#Correct Entity : 9152\r\n",
      "Entity  precision: 0.4716\r\n",
      "Entity  recall: 0.6944\r\n",
      "Entity  F: 0.5617\r\n",
      "\r\n",
      "#Correct Sentiment : 7644\r\n",
      "Sentiment  precision: 0.3939\r\n",
      "Sentiment  recall: 0.5800\r\n",
      "Sentiment  F: 0.4692\r\n"
     ]
    }
   ],
   "source": [
    "main(EN_train, EN_out_2, EN_dev_x)\n",
    "! python {EVAL_script} {EN_dev_y} {EN_out_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 1478\r\n",
      "#Entity in prediction: 9373\r\n",
      "\r\n",
      "#Correct Entity : 765\r\n",
      "Entity  precision: 0.0816\r\n",
      "Entity  recall: 0.5176\r\n",
      "Entity  F: 0.1410\r\n",
      "\r\n",
      "#Correct Sentiment : 285\r\n",
      "Sentiment  precision: 0.0304\r\n",
      "Sentiment  recall: 0.1928\r\n",
      "Sentiment  F: 0.0525\r\n"
     ]
    }
   ],
   "source": [
    "main(CN_train, CN_out_2, CN_dev_x)\n",
    "! python {EVAL_script} {CN_dev_y} {CN_out_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition_matrix shape (transition_from, transition_to):  (44, 44)\n"
     ]
    }
   ],
   "source": [
    "def transition(y, tags, tag2index):\n",
    "    SOS = tag2index['SOS']\n",
    "    EOS = tag2index['EOS']\n",
    "    y = [[SOS]+o+[EOS] for o in y]\n",
    "    transition = np.zeros((len(tags), len(tags)))\n",
    "    \n",
    "    for yy in y:\n",
    "        for i in range(len(yy)-1):\n",
    "            start = yy[i]\n",
    "            end = yy[i+1]\n",
    "            transition[start, end] += 1\n",
    "    \n",
    "    transition = transition/np.sum(transition, axis=1)\n",
    "    np.nan_to_num(transition, 0)\n",
    "    return transition\n",
    "transition_matrix = transition(y, tags, tag2index)\n",
    "print(\"transition_matrix shape (transition_from, transition_to): \", transition_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viterbi decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_score(x, transition_matrix, emission_matrix, sos_index, tags):\n",
    "    \"\"\"transition_matrix: before log\n",
    "    x: [1, 2, 4, 19, ...]\n",
    "    transition: after log\n",
    "    score: （len(x)+1, #tags)\n",
    "    \"\"\"\n",
    "    # correct way of initialization\n",
    "    score = np.zeros( (len(x)+2, len(tags)) )\n",
    "    score[0, :] = -np.inf\n",
    "    score[0, sos_index] = 0\n",
    "\n",
    "    argmax = np.zeros( (len(x)+1, len(tags)), dtype=np.int)\n",
    "    transition, emission = np.log(transition_matrix), np.log(emission_matrix)\n",
    "    for step in range(1, len(score)):\n",
    "        for state in range(len(score[step])):\n",
    "            previous_score = score[step-1]\n",
    "            t_score = transition[:, state]\n",
    "            top1 = (previous_score + t_score).argsort()[-1]\n",
    "            argmax[step-1, state] = top1\n",
    "            if step==len(x)+1:\n",
    "                score[step, state] = (previous_score + t_score)[top1]\n",
    "            else:\n",
    "                x_word_index = x[step-1]\n",
    "                e_score = emission[x_word_index, state]\n",
    "                score[step, state] = (previous_score + t_score)[top1] + e_score\n",
    "#     print(score[-1, -1])\n",
    "    return score[1:,:], argmax\n",
    "\n",
    "def viterbi_decode_path(argmax, eos_index):\n",
    "    \"\"\"\n",
    "    argmax: (len(x)+1, #tags)\n",
    "    eos_Index: EOS tag index in tags\n",
    "    Returns:\n",
    "            path: (len(x), )\"\"\"\n",
    "    path = []\n",
    "    temp_arg = eos_index\n",
    "    for i in range(len(argmax)-1, -1, -1):\n",
    "        temp_arg = argmax[i, temp_arg]\n",
    "        path.append(temp_arg)\n",
    "    return path\n",
    "\n",
    "def viterbi(x, transition_matrix, emission_matrix, sos_index, eos_index, tags):\n",
    "    \"\"\"\n",
    "    x: list of int\n",
    "    transition_matrix: (#tags(with eos,sos), #tags(with eos,sos))\n",
    "    emission_matrix: (#vocab_size,#tags(with eos,sos) )\"\"\"\n",
    "    score, argmax = viterbi_score(x, transition_matrix, emission_matrix, sos_index, tags)\n",
    "    path = viterbi_decode_path(argmax, eos_index)\n",
    "    return path[:-1][::-1]\n",
    "\n",
    "def viterbi_decode_batch(x, transition_matrix, emission_matrix, sos_index, eos_index, \n",
    "                         output_filename, dev_x_filename, word2index, tags):\n",
    "    with open(output_filename, 'w') as f:\n",
    "        words, dev_x = get_test_data(dev_x_filename, word2index)\n",
    "        for i, (ws,o) in enumerate(zip(words, dev_x)):\n",
    "            path = viterbi(o, transition_matrix, emission_matrix, sos_index, eos_index, tags)\n",
    "            for w, p in zip(ws, path):\n",
    "                f.write(w + ' ' + tags[p] + '\\n')\n",
    "            f.write('\\n')\n",
    "            \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def q3(train_file, output_filename, dev_x_filename):\n",
    "    # read data\n",
    "    words, labels = get_train_data(train_file)\n",
    "    # create vocab\n",
    "    tags = list(set([oo for o in labels for oo in o])) + ['SOS', 'EOS']\n",
    "    tag2index = {o:i for i,o in enumerate(tags)}\n",
    "    vocab_count = Counter([oo for o in words for oo in o])\n",
    "    vocab = [o for o, v in dict(vocab_count).items() if v>=3] + ['#UNK#']\n",
    "    word2index = defaultdict(int)\n",
    "    for i,o in enumerate(vocab): word2index[o] = i+1\n",
    "    # text to int\n",
    "    x = [[word2index[oo] for oo in o] for o in words]\n",
    "    y = [[tag2index[oo] for oo in o] for o in labels]\n",
    "    # training emission\n",
    "    emission_matrix = emission(x, y, vocab, tags)\n",
    "    emission_matrix += 1e-9\n",
    "    print(\"emission_matrix shape:\", emission_matrix.shape)\n",
    "    # training transition\n",
    "    transition_matrix = transition(y, tags, tag2index)\n",
    "    print(\"transition_matrix shape\", transition_matrix.shape)\n",
    "    # decoding\n",
    "    viterbi_decode_batch(x, transition_matrix, emission_matrix,  tags.index('SOS'), tags.index('EOS'), \n",
    "                         output_filename, dev_x_filename, word2index, tags)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission_matrix shape: (2698, 44)\n",
      "transition_matrix shape (44, 44)\n",
      "\n",
      "#Entity in gold data: 8408\n",
      "#Entity in prediction: 8588\n",
      "\n",
      "#Correct Entity : 6703\n",
      "Entity  precision: 0.7805\n",
      "Entity  recall: 0.7972\n",
      "Entity  F: 0.7888\n",
      "\n",
      "#Correct Sentiment : 5993\n",
      "Sentiment  precision: 0.6978\n",
      "Sentiment  recall: 0.7128\n",
      "Sentiment  F: 0.7052\n"
     ]
    }
   ],
   "source": [
    "q3(AL_train, AL_out_3, AL_dev_x)\n",
    "! python {EVAL_script} {AL_dev_y} {AL_out_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission_matrix shape: (6187, 23)\n",
      "transition_matrix shape (23, 23)\n",
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 13056\n",
      "\n",
      "#Correct Entity : 11091\n",
      "Entity  precision: 0.8495\n",
      "Entity  recall: 0.8416\n",
      "Entity  F: 0.8455\n",
      "\n",
      "#Correct Sentiment : 10667\n",
      "Sentiment  precision: 0.8170\n",
      "Sentiment  recall: 0.8094\n",
      "Sentiment  F: 0.8132\n"
     ]
    }
   ],
   "source": [
    "q3(EN_train, EN_out_3, EN_dev_x)\n",
    "! python {EVAL_script} {EN_dev_y} {EN_out_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 4537\r\n",
      "#Entity in prediction: 4335\r\n",
      "\r\n",
      "#Correct Entity : 1387\r\n",
      "Entity  precision: 0.3200\r\n",
      "Entity  recall: 0.3057\r\n",
      "Entity  F: 0.3127\r\n",
      "\r\n",
      "#Correct Sentiment : 801\r\n",
      "Sentiment  precision: 0.1848\r\n",
      "Sentiment  recall: 0.1765\r\n",
      "Sentiment  F: 0.1806\r\n"
     ]
    }
   ],
   "source": [
    "q3(SG_train, SG_out_3, SG_dev_x)\n",
    "! python {EVAL_script} {SG_dev_y} {SG_out_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 1478\r\n",
      "#Entity in prediction: 923\r\n",
      "\r\n",
      "#Correct Entity : 315\r\n",
      "Entity  precision: 0.3413\r\n",
      "Entity  recall: 0.2131\r\n",
      "Entity  F: 0.2624\r\n",
      "\r\n",
      "#Correct Sentiment : 210\r\n",
      "Sentiment  precision: 0.2275\r\n",
      "Sentiment  recall: 0.1421\r\n",
      "Sentiment  F: 0.1749\r\n"
     ]
    }
   ],
   "source": [
    "q3(CN_train, CN_out_3, CN_dev_x)\n",
    "! python {EVAL_script} {CN_dev_y} {CN_out_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 Top 7th sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_score_top_k(x, transition_matrix, emission_matrix, sos_index, tags, k=7):\n",
    "    \"\"\"transition_matrix: before log\n",
    "    transition: after log\n",
    "    score: （len(x)+1, #tags, 7)\n",
    "    argmax: (len(x)+1, #tags, 7)\n",
    "    time complexity: O(knt^2)\n",
    "    \"\"\"\n",
    "    # correct way of initialization\n",
    "    score = np.zeros( (len(x)+2, len(tags), k) )\n",
    "    score[0, :, :] = -np.inf\n",
    "    score[0, sos_index, :] = 0\n",
    "    argmax = np.zeros( (len(x)+1, len(tags), k), dtype=np.int64)\n",
    "    transition, emission = np.log(transition_matrix), np.log(emission_matrix)\n",
    "    \n",
    "    for step in range(1, len(score)):\n",
    "        for state in range(len(score[step])): # state means tag\n",
    "            previous_score = score[step-1] # (num_of_tags, 7)\n",
    "            t_score = transition[:, state] # (num_of_tags,)\n",
    "            \n",
    "            previous_all_scores = (previous_score + t_score[:,np.newaxis]).flatten() # (7*num_of_tags, )\n",
    "            top_7_arg = previous_all_scores.argsort()[-k:][::-1] # (7, )\n",
    "            argmax[step-1, state] = top_7_arg // 7\n",
    "            top_7_scores = previous_all_scores[top_7_arg] # (7,)\n",
    "            if step-1==len(x):\n",
    "                # last step\n",
    "                score[step, state] = top_7_scores\n",
    "            else:\n",
    "                # all steps before last step\n",
    "                x_word_index = x[step-1]\n",
    "                e_score = emission[x_word_index, state] # (1,)\n",
    "                score[step, state] = top_7_scores + e_score\n",
    "    return score[1:,:, :], argmax\n",
    "\n",
    "\n",
    "\n",
    "def viterbi_decode_path_top_k(argmax, eos_index, k=7):\n",
    "    \"\"\"\n",
    "    argmax: (len(x)+1, #tags, 7)\n",
    "    eos_Index: EOS tag index in tags\n",
    "    Returns:\n",
    "            path: (len(x),)\n",
    "    \"\"\"\n",
    "    path = []\n",
    "    temp_state = eos_index\n",
    "    \n",
    "    for i in range(len(argmax)-1, -1, -1):\n",
    "        temp_state = argmax[i, temp_state][-1] if i == len(argmax)-1 else argmax[i, temp_state][0] # (1,)\n",
    "        path.append(temp_state)\n",
    "    return path\n",
    "\n",
    "\n",
    "def viterbi_top_k(x, transition_matrix, emission_matrix, sos_index, eos_index, tags):\n",
    "    \"\"\"\n",
    "    x: list of int\n",
    "    transition_matrix: (#tags(with eos,sos), #tags(with eos,sos))\n",
    "    emission_matrix: (#vocab_size,#tags(with eos,sos) )\"\"\"\n",
    "    score, argmax = viterbi_score_top_k(x, transition_matrix, emission_matrix, sos_index, tags, 7)\n",
    "    path = viterbi_decode_path_top_k(argmax, eos_index, 7)\n",
    "    return path[:-1][::-1]\n",
    "\n",
    "def viterbi_decode_batch_top_k(x, transition_matrix, emission_matrix, sos_index, eos_index, \n",
    "                         output_filename, dev_x_filename, word2index, tags):\n",
    "    with open(output_filename, 'w') as f:\n",
    "        words, dev_x = get_test_data(dev_x_filename, word2index)\n",
    "        for i, (ws,o) in enumerate(zip(words, dev_x)):\n",
    "            path = viterbi_top_k(o, transition_matrix, emission_matrix, sos_index, eos_index, tags)\n",
    "            for w, p in zip(ws, path):\n",
    "                f.write(w + ' ' + tags[p] + '\\n')\n",
    "            f.write('\\n')   \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q4(train_file, output_filename, dev_x_filename):\n",
    "    # read data\n",
    "    words, labels = get_train_data(train_file)\n",
    "    # create vocab\n",
    "    tags = list(set([oo for o in labels for oo in o])) + ['SOS', 'EOS']\n",
    "    tag2index = {o:i for i,o in enumerate(tags)}\n",
    "    vocab_count = Counter([oo for o in words for oo in o])\n",
    "    vocab = [o for o, v in dict(vocab_count).items() if v>=3] + ['#UNK#']\n",
    "    word2index = defaultdict(int)\n",
    "    for i,o in enumerate(vocab): word2index[o] = i+1\n",
    "    # text to int\n",
    "    x = [[word2index[oo] for oo in o] for o in words]\n",
    "    y = [[tag2index[oo] for oo in o] for o in labels]\n",
    "    # training emission\n",
    "    emission_matrix = emission(x, y, vocab, tags)\n",
    "    emission_matrix += 1e-9\n",
    "    # training transition\n",
    "    transition_matrix = transition(y, tags, tag2index)\n",
    "    # decoding\n",
    "    viterbi_decode_batch_top_k(x, transition_matrix, emission_matrix,  tags.index('SOS'), tags.index('EOS'), \n",
    "                         output_filename, dev_x_filename, word2index, tags)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 8408\r\n",
      "#Entity in prediction: 8588\r\n",
      "\r\n",
      "#Correct Entity : 6703\r\n",
      "Entity  precision: 0.7805\r\n",
      "Entity  recall: 0.7972\r\n",
      "Entity  F: 0.7888\r\n",
      "\r\n",
      "#Correct Sentiment : 5993\r\n",
      "Sentiment  precision: 0.6978\r\n",
      "Sentiment  recall: 0.7128\r\n",
      "Sentiment  F: 0.7052\r\n"
     ]
    }
   ],
   "source": [
    "q4(AL_train, AL_out_4, AL_dev_x)\n",
    "! python {EVAL_script} {AL_dev_y} {AL_out_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 13179\r\n",
      "#Entity in prediction: 13056\r\n",
      "\r\n",
      "#Correct Entity : 11091\r\n",
      "Entity  precision: 0.8495\r\n",
      "Entity  recall: 0.8416\r\n",
      "Entity  F: 0.8455\r\n",
      "\r\n",
      "#Correct Sentiment : 10667\r\n",
      "Sentiment  precision: 0.8170\r\n",
      "Sentiment  recall: 0.8094\r\n",
      "Sentiment  F: 0.8132\r\n"
     ]
    }
   ],
   "source": [
    "q4(EN_train, EN_out_4, EN_dev_x)\n",
    "! python {EVAL_script} {EN_dev_y} {EN_out_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
